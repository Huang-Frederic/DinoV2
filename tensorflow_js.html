<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>DINOv2 Model Inference</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        text-align: center;
      }
      .image-container {
        display: flex;
        justify-content: space-around;
        margin-top: 20px;
      }
      .image-container img {
        max-width: 100%;
        height: auto;
      }
    </style>
  </head>
  <body>
    <h1>Traitement de l'image avec DINOv2</h1>

    <input
      type="file"
      id="imageInput"
      accept="image/*"
      onchange="handleImageUpload(event)"
    />
    <br /><br />
    <div class="image-container">
      <div>
        <h3>Image originale</h3>
        <img id="originalImage" src="" alt="Image Originale" />
      </div>
      <div>
        <h3>Carte de caractéristiques</h3>
        <canvas id="featureMapCanvas"></canvas>
      </div>
      <div>
        <h3>Image superposée</h3>
        <canvas id="superposedCanvas"></canvas>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0/dist/tf.min.js"></script>

    <script>
      function handleImageUpload(event) {
        const file = event.target.files[0];
        const reader = new FileReader();
        reader.onload = function (e) {
          const img = new Image();
          img.src = e.target.result;
          img.onload = function () {
            processImage(img);
          };
        };
        reader.readAsDataURL(file);
      }

      async function processImage(image) {
        document.getElementById("originalImage").src = image.src;

        let inputTensor = tf.browser.fromPixels(image).toFloat();

        inputTensor = tf.image.resizeBilinear(inputTensor, [518, 518]);

        inputTensor = inputTensor.div(tf.scalar(255));
        inputTensor = inputTensor.sub(tf.scalar(0.5)).div(tf.scalar(0.5));

        const model = await tf.loadLayersModel(
          "models/vit_large_patch14_dinov2/config.json"
        );

        const predictions = model.predict(inputTensor.expandDims(0));

        const featureMap = predictions[0].arraySync();

        const featureMapCanvas = document.getElementById("featureMapCanvas");
        const featureMapCtx = featureMapCanvas.getContext("2d");
        featureMapCanvas.width = featureMap[0].length;
        featureMapCanvas.height = featureMap.length;

        const imageData = featureMapCtx.createImageData(
          featureMap[0].length,
          featureMap.length
        );
        for (let i = 0; i < featureMap.length; i++) {
          for (let j = 0; j < featureMap[i].length; j++) {
            const idx = (i * featureMap[i].length + j) * 4;
            const value = featureMap[i][j];
            imageData.data[idx] = value * 255;
            imageData.data[idx + 1] = value * 255;
            imageData.data[idx + 2] = value * 255;
            imageData.data[idx + 3] = 255;
          }
        }
        featureMapCtx.putImageData(imageData, 0, 0);

        const superposedCanvas = document.getElementById("superposedCanvas");
        const superposedCtx = superposedCanvas.getContext("2d");
        superposedCanvas.width = image.width;
        superposedCanvas.height = image.height;

        superposedCtx.globalAlpha = 0.9;
        superposedCtx.drawImage(image, 0, 0);
        superposedCtx.globalAlpha = 0.1;
        superposedCtx.drawImage(featureMapCanvas, 0, 0);
      }
    </script>
  </body>
</html>
